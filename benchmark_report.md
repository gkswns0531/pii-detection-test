# PII 검출 소형 LLM 벤치마크 종합 보고서

**작성일**: 2026-02-12
**평가 환경**: NVIDIA B200 (183GB VRAM), vLLM v0.15.1, Structured JSON Output
**테스트 데이터**: 299개 케이스 (all_test_cases 99개 + name_address_200 200개)
**베이스라인 모델**: Qwen3-30B-A3B-Instruct-2507-FP8 (30B MoE, 활성 3B)

---

## 1. 개요

한국어 문서에서 12개 카테고리의 개인정보(PII)를 검출하는 태스크에 대해, 파라미터 크기별 소형 LLM의 성능을 벤치마킹하였다. 모든 모델은 동일한 프롬프트와 JSON Schema 기반 structured output을 사용하며, temperature=0.0, concurrency=200으로 평가하였다.

### PII 카테고리 (12개)
이름, 주소, 주민등록번호, 여권번호, 운전면허번호, 이메일, IP주소, 전화번호, 계좌번호, 카드번호, 생년월일, 기타_고유식별정보

### 평가 지표
- **Acc (Accuracy)**: 299개 케이스 중 완벽 통과(모든 카테고리 정확히 일치) 비율
- **F1 (Micro)**: 전체 TP/FP/FN 기반 Micro-average F1 Score
- **P (Precision)**: TP / (TP + FP)
- **R (Recall)**: TP / (TP + FN)

---

## 2. 전체 결과 요약

| Rank | Model | Params | Category | Acc | F1 | P | R |
|------|-------|--------|----------|-----|-----|---|---|
| 1 | **Qwen3-30B-A3B** (Baseline) | 30B (3B active) | Baseline | **90.30%** | **94.90%** | - | - |
| 2 | **Qwen3-8B** | 8.0B | 3-10B | **79.60%** | **90.04%** | 87.58% | 92.65% |
| 3 | **Qwen3-4B-Instruct-2507** | 4.0B | 3-10B | **79.60%** | **87.79%** | 86.68% | 88.92% |
| 4 | Qwen3-1.7B | 1.7B | 1-3B | 62.54% | 77.22% | 80.17% | 74.48% |
| 5 | SmolLM3-3B | 3.0B | 1-3B | 60.20% | 70.75% | 85.56% | 60.31% |
| 6 | Falcon-H1R-7B | 7.0B | 3-10B | 47.49% | 69.66% | 67.43% | 72.04% |
| 7 | Gemma-3-4B-IT | 4.0B | 3-10B | 9.70% | 42.85% | 28.54% | 85.95% |
| 8 | Qwen3-0.6B | 0.6B | ≤1B | 13.71% | 39.86% | 41.65% | 38.22% |
| 9 | Gemma-3-1B-IT | 1.0B | ≤1B | 13.38% | 39.01% | 39.24% | 38.79% |
| 10 | Llama-3.2-3B-Instruct | 3.0B | 1-3B | 16.72% | 26.44% | 16.50% | 66.49% |
| 11 | Llama-3.2-1B-Instruct | 1.0B | ≤1B | 6.02% | 16.83% | 10.95% | 36.34% |
| - | EXAONE-3.5-2.4B / 7.8B | 2.4B / 7.8B | - | *스킵* | *transformers 호환 이슈* | | |

---

## 3. 카테고리별 세부 분석

### ≤1B 카테고리

| Model | Acc | F1 | 특이사항 |
|-------|-----|-----|---------|
| Qwen3-0.6B | 13.71% | 39.86% | 0.6B로 1B 모델과 동급 성능 |
| Gemma-3-1B-IT | 13.38% | 39.01% | Qwen3-0.6B와 거의 동일 |
| Llama-3.2-1B | 6.02% | 16.83% | FP 2,294개 폭발 (기타_고유식별정보 1,062 FP) |

**소결**: ≤1B 모델은 한국어 PII 검출에 실용적이지 않음. F1 40% 미만으로, 프로덕션 사용 불가.

### 1B-3B 카테고리

| Model | Acc | F1 | 특이사항 |
|-------|-----|-----|---------|
| Qwen3-1.7B | 62.54% | 77.22% | 1.7B로 3B 모델 능가 |
| SmolLM3-3B | 60.20% | 70.75% | P=85.56% 높지만 R=60.31% 낮음 (보수적) |
| Llama-3.2-3B | 16.72% | 26.44% | 여전히 FP 폭발 |

**소결**: Qwen3-1.7B가 1.7B 파라미터로 77% F1 달성. ≤1B 대비 2배 성능 점프. SmolLM3-3B는 Precision 높아 false positive에 민감한 환경에 적합.

### 3-10B 카테고리

| Model | Acc | F1 | 특이사항 |
|-------|-----|-----|---------|
| Qwen3-8B | 79.60% | 90.04% | 30B 대비 5%p 차이, 가장 근접 |
| Qwen3-4B | 79.60% | 87.79% | 4B로 8B에 근접, 가성비 최강 |
| Falcon-H1R-7B | 47.49% | 69.66% | 이름 FP 228개 (기관명/직책 혼동) |
| Gemma-3-4B-IT | 9.70% | 42.85% | R=85.95%이지만 P=28.54% — FP 1,670개 |

**소결**: Qwen3-8B가 F1 90%로 30B에 가장 근접. Qwen3-4B는 절반 크기로 거의 동급 성능을 내어 가성비 최강. Falcon은 범용 벤치마크 대비 한국어 PII에서 부진. Gemma-4B는 모든 것을 PII로 판정하는 경향.

---

## 4. 모델 계열별 분석

### Qwen3 계열 (Alibaba) — 전 구간 1위
| Size | F1 | 성능 대비 |
|------|-----|----------|
| 0.6B | 39.86% | ≤1B 1위 |
| 1.7B | 77.22% | 1-3B 1위 |
| 4.0B | 87.79% | 3-10B 2위 |
| 8.0B | 90.04% | 3-10B 1위 |
| 30B (baseline) | 94.90% | 전체 1위 |

Qwen3 계열은 한국어 PII 검출에서 압도적. 119개 언어 지원과 한국어 학습 데이터 품질이 핵심 요인으로 추정.

### Llama 계열 (Meta) — FP 폭발 문제
1B와 3B 모두 False Positive가 극심. 특히 기타_고유식별정보 카테고리에서 관련 없는 텍스트를 대량 예측. 한국어 이해력 부족이 원인.

### Gemma 계열 (Google) — 높은 Recall, 낮은 Precision
1B에서는 Qwen과 동급이나, 4B에서도 P=28.54%로 실용 불가. 과탐(over-detection) 경향이 심함.

### SmolLM3 (HuggingFace) — 보수적 예측
3B에서 P=85.56%로 높은 정밀도. Recall이 60%로 낮아 누락이 많지만, FP 민감 환경에서는 활용 가능.

### Falcon-H1R (TII) — 한국어 PII에 부적합
7B Transformer-Mamba2 하이브리드로 범용 벤치마크에서는 강력하나, 한국어 PII 검출에서는 기관명/직책을 이름으로 오탐하는 문제가 두드러짐.

---

## 5. 난이도별 성능 비교 (상위 4개 모델)

| Model | EASY F1 | MEDIUM F1 | HARD F1 |
|-------|---------|-----------|---------|
| Qwen3-30B | ~95% | ~93% | ~88% |
| Qwen3-8B | 95.51% | 90.91% | 81.96% |
| Qwen3-4B | 94.12% | 89.22% | 77.89% |
| Qwen3-1.7B | 82.94% | 81.46% | 65.51% |

EASY 케이스에서는 4B 이상이면 94%+로 충분. HARD 케이스(OCR 오류, 난독화, 마스킹)에서 모델 크기에 따른 차이가 극대화됨.

---

## 6. 실행 불가 모델

| Model | 사유 |
|-------|------|
| EXAONE-3.5-2.4B-Instruct | transformers 4.57.3에 `RopeParameters` 미지원 (custom code 호환 이슈) |
| EXAONE-3.5-7.8B-Instruct | 동일 사유 |

---

## 7. 결론 및 권장사항

### 프로덕션 권장 모델
1. **Qwen3-8B** (F1=90.04%) — 성능 최우선 시. 30B 대비 5%p 차이로 충분히 실용적.
2. **Qwen3-4B-Instruct-2507** (F1=87.79%) — 가성비 최우선 시. 4B로 8B에 근접한 성능.
3. **Qwen3-1.7B** (F1=77.22%) — 엣지/모바일 배포 시. 1.7B로 77% F1은 놀라운 성능.

### 비권장 모델
- Llama 계열: 한국어 PII 태스크에 부적합 (FP 폭발)
- Gemma 계열: Precision 너무 낮아 실용 불가
- ≤1B 모델 전체: F1 40% 미만으로 프로덕션 불가

### 파라미터 대비 성능 효율
```
0.6B → F1 40%  (기본 수준)
1.7B → F1 77%  (+37%p, 가장 큰 점프)
4.0B → F1 88%  (+11%p)
8.0B → F1 90%  (+2%p)
30B  → F1 95%  (+5%p)
```

**1.7B → 4B 구간이 가성비 최적점**. 4B 이후 성능 향상이 급감하므로, 리소스 제약이 있다면 Qwen3-4B가 최선의 선택.

---

## 8. 파일 목록

| 파일 | 설명 |
|------|------|
| `combined_test_cases.json` | 통합 테스트 데이터 (299개) |
| `run_pii_evaluation.py` | 평가 스크립트 |
| `results_combined_final.json` | Qwen3-30B 베이스라인 결과 |
| `results_qwen3_0.6b.json` | Qwen3-0.6B 결과 |
| `results_gemma3_1b.json` | Gemma-3-1B-IT 결과 |
| `results_llama32_1b.json` | Llama-3.2-1B 결과 |
| `results_qwen3_1.7b.json` | Qwen3-1.7B 결과 |
| `results_smollm3_3b.json` | SmolLM3-3B 결과 |
| `results_llama32_3b.json` | Llama-3.2-3B 결과 |
| `results_qwen3_4b.json` | Qwen3-4B 결과 |
| `results_qwen3_8b.json` | Qwen3-8B 결과 |
| `results_falcon_h1r_7b.json` | Falcon-H1R-7B 결과 |
| `results_gemma3_4b.json` | Gemma-3-4B-IT 결과 |
| `model_benchmark_lists.md` | 모델 Top 10 리스트 (카테고리별) |
| `benchmark_report.md` | 본 보고서 |
